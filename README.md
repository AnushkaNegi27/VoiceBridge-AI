# ğŸš€ VoiceBridge-AI

<div align="center">

  **An end-to-end AI system for speech-to-speech and video translation across multiple languages.**

  [Documentation](https://docs-link.com) <!-- TODO: Add documentation link -->
</div>

---

## ğŸ“– Overview

VoiceBridge-AI is a powerful, full-stack application designed to break down language barriers in multimedia content. It provides a comprehensive solution for real-time or offline speech-to-speech and video translation. By integrating advanced Automatic Speech Recognition (ASR), Neural Machine Translation (NMT), and Text-to-Speech (TTS) capabilities, VoiceBridge-AI processes audio and video input, translates the spoken content into a target language, and synthesizes it into natural-sounding speech, making global communication seamless and accessible. This system is ideal for transcribing lectures, translating interviews, localizing video content, and much more.

---

## âœ¨ Features

-   ğŸ¯ **End-to-End AI System:** Fully integrated pipeline from speech input to translated voice output.
-   ğŸ—£ï¸ **Automatic Speech Recognition (ASR):** Accurately transcribes spoken language from audio and video inputs into text.
-   ğŸŒ **Neural Machine Translation (NMT):** Translates recognized text across multiple languages using state-of-the-art neural models.
-   ğŸ™ï¸ **Text-to-Speech (TTS):** Synthesizes translated text into natural-sounding speech in the target language.
-   ğŸ¬ **Video Content Translation:** Processes video files, extracting audio for translation and potentially re-integrating translated audio or captions.
-   ğŸŒ **Multilingual Support:** Designed to handle translation between a diverse range of languages.
-   âš¡ **Scalable Architecture:** Modular design supporting a powerful Python backend for AI inference and a responsive web frontend.

---


## ğŸ§  How It Works

1. User uploads an **audio or video file**
2. Speech is transcribed using **Whisper (ASR)**
3. Transcribed text is translated using **Transformer-based NMT**
4. Translated text is converted into speech
5. Output is returned as:
   - Translated audio file, or
   - Video with translated audio merged

---
## ğŸ”Š Text-to-Speech Strategy

VoiceBridge-AI uses a **hybrid TTS approach**:

- **Piper TTS**  
  - Lightweight, offline, fast inference  
  - Used for supported languages  

- **Google gTTS (fallback)**  
  - Ensures wider language coverage  
  - Used when a language is not supported by Piper  

This approach balances **performance**, **offline capability**, and **language support**.

---

## ğŸ–¥ï¸ Screenshots

<!-- TODO: Add actual screenshots of the application's user interface -->
![Screenshot of VoiceBridge-AI Dashboard](path-to-dashboard-screenshot.png)
![Screenshot of Translation in Progress](path-to-translation-screenshot.png)

---

## ğŸ› ï¸ Tech Stack

### Backend & AI
- Python
- FastAPI
- Uvicorn
- Whisper (Open-source ASR)
- Hugging Face Transformers (Translation)
- Piper TTS (Offline Text-to-Speech)
- Google gTTS (Fallback TTS)
- FFmpeg

### Frontend
- React
- Vite
- Tailwind CSS

---

## ğŸ“‚ Project Structure

```text
VoiceBridge-AI/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ routes/
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ asr.py
â”‚   â”‚   â”œâ”€â”€ translation.py
â”‚   â”‚   â”œâ”€â”€ tts.py
â”‚   â”‚   â”œâ”€â”€ pipeline.py
â”‚   â”‚   â””â”€â”€ video_pipeline.py
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ public/
â”‚   â””â”€â”€ package.json
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ audio_preprocessing.ipynb
â”‚   â”œâ”€â”€ whisper_training.ipynb
â”‚   â””â”€â”€ whisper_inference.ipynb
â”‚
â”œâ”€â”€ .gitignore
â”œâ”€â”€ LICENSE
â””â”€â”€ README.md

```

---

## âš™ï¸ Installation & Setup

**1ï¸âƒ£ Clone the Repository**
```
git clone https://github.com/AnushkaNegi27/VoiceBridge-AI.git
cd VoiceBridge-AI
```

**2ï¸âƒ£ Backend Setup (Python Virtual Environment)**
```
cd backend

# Create virtual environment
python -m venv venv

# Activate virtual environment
# Windows
venv\Scripts\activate

# Linux / Mac
source venv/bin/activate

```
Install Dependencies:
```
pip install -r requirements.txt
```
Run backend server:
```
uvicorn app:app --reload
```
Backend will run at:
```
http://127.0.0.1:8000
```

**3ï¸âƒ£ Frontend Setup (React)**
```
cd ../frontend
npm install
npm run dev

```

Frontend will run at:
```
http://localhost:5173
```

---

## ğŸ¯ Project Goals

-Build a real-world AI pipeline, not just a demo

-Emphasize modular design and extensibility

-Support audio + video workflows

-Balance performance and language coverage

---

## ğŸ”® Future Improvements

ğŸ¤ Real-time microphone translation

â±ï¸ Streaming inference for long files

ğŸ“ Subtitle generation

â˜ï¸ Cloud deployment (Docker / CI-CD)

---

## ğŸ‘¤ Author

Anushka Negi

---

## ğŸ“„ License

This project is licensed under the MIT License.



